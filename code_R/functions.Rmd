---
title: "R Notebook"
output: html_notebook
---


Permet de faire des modeles de cox univariés et d'avoir les resultats sous la forme extract_coxReg (donc dataframe).

```{r}
cox_univar = function(time, evt, param, dt, round = T, d.round = 2, alpha = 0.05, interaction = F, var.inter){
  
  # time : time-to-event
  # evt : variable d'evenement (binaire)
  # var : liste de variables explicatives
  # dt : dateframe contennant toues les var citées plus haut
  # round : variable booléenne d'arondis, F par défaut. Valeur T utile pour les graphes
  # d.round : nb de décimale conservée aprés arrondis, 2 par défaut
  # alpha : risque de première éspèce. 5% par défaut
  # interaction : variable booléenne sur inclusion d'une interraction. FALSE par defaut
  # var.inter : variable d'interraction, uniquement si interraction vaut TRUE
  
  
  # On s'assure que le time-to-event et l'event sont bien numériques
  time = as.numeric(as.character(dt[,time]))
  evt = as.numeric(as.character(dt[,evt]))
  
  # On fit le modèle
  if(interaction == T){
    model = coxph(Surv(time,evt) ~ dt[,param] + dt[,param]*dt[,var.inter], data = dt)
    }
  else
    model = coxph(Surv(time,evt) ~ dt[,param], data = dt)

  
  summary = summary(model)
  
  # test de shonfeld pour vérifier l'hypothèse de proportionnalité des risques
  test.shonfeld = cox.zph(model)
  
  # Récupération du c_index
  c_index = concordance(model)$concordance
  
  # Construction du dataframe final arrondi ou non
  if (round == T){

     df = data.frame("Name" = param,
                     "HR" = round(summary$coefficient[length(summary$coefficient[,2]),2],d.round),
                     "IC" = paste0("[", round(summary$conf.int[length(summary$conf.int[,3]),3],d.round +1), " ; ", round(summary$conf.int[length(summary$conf.int[,4]),4],d.round+1), "]"),
                     "p.value" = signif(summary$coefficient[length(summary$coefficient[,5]),5],3),
                     "pv_signif" = ifelse(summary$coefficient[length(summary$coefficient[,5]),5] <= alpha, "*"," "),
                     "p.shonfeld" = signif(test.shonfeld$table[dim(test.shonfeld$table)[1],dim(test.shonfeld$table)[2]],d.round+1),
                     "n" = model$n,
                     "n.events" = model$nevent,
                     "c_index" = round(c_index,3)
                     )
   
   
    return(list("res_df"=df, "model" = model))
  } 
  
  else if (round == F){
    
    df = data.frame("Name" = param,
                    "HR" = summary$coefficient[length(summary$coefficient[,2]),2],
                    "ICinf" = summary$conf.int[length(summary$conf.int[,3]),3],
                    "ICsup" = summary$conf.int[length(summary$conf.int[,4]),4],
                    "p.value" = summary$coefficient[length(summary$coefficient[,5]),5],
                    "pv_signif" = ifelse(summary$coefficient[length(summary$coefficient[,5]),5] <= alpha, 1,0),
                    "p.shonfeld" = signif(test.shonfeld$table[dim(test.shonfeld$table)[1],dim(test.shonfeld$table)[2]],d.round+1),
                    "Hyp.Prop.verif" = ifelse(test.shonfeld$table[dim(test.shonfeld$table)[1],dim(test.shonfeld$table)[2]] <= alpha ,0,1),
                    "n" = model$n,
                    "n.events" = model$nevent,
                    "c_index" = c_index
                    )
  
    return(df)
  
  }
}
```

cox univariés avec l'âge comme echelle de temps
```{r}
cox_univar_as = function(t1, t2, evt,var, dt, round = T, d.round = 2, alpha = 0.05, interaction = F, var.inter){
  
  # t1 : age à baseline
  # t2 : age à l'évenement
  # evt : variable d'evenement (binaire)
  # var : liste de variables explicatives
  # dt : dateframe contennant toues les var citées plus haut
  # round : variable booléenne d'arondis, F par défaut. Valeur T utile pour les graphes
  # d.round : nb de décimale conservée aprés arrondis, 2 par défaut
  # alpha : risque de première éspèce. 5% par défaut
  # interaction : variable booléenne sur inclusion d'une interraction. FALSE par defaut
  # var.inter : variable d'interraction, uniquement si interraction vaut TRUE
  
  
  # On s'assure que le time-to-event et l'event sont bien numériques
  t1 = as.numeric(as.character(dt[,t1]))
  t2 = as.numeric(as.character(dt[,t2])) 
  evt = as.numeric(as.character(dt[,evt]))
  
  # On fit le modèle
  if(interaction == T){
    model = coxph(Surv(t1,t2,evt) ~ dt[,var] + dt[,var]*dt[,var.inter], data = dt)}
  else
    model = coxph(Surv(t1,t2,evt) ~ dt[,var], data = dt)
  
  summary = summary(model)
  
  # test de shonfeld pour vérifier l'hypothèse de proportionnalité des risques
  test.shonfeld = cox.zph(model)
  
  # Récupération du c_index
  c_index = concordance(model)$concordance
  
  # Construction du dataframe final arrondi ou non
   if (round == T){
     
     df = data.frame("Name" = var,
                     "HR" = round(summary$coefficient[length(summary$coefficient[,2]),2],d.round),
                     "IC" = paste0("[", round(summary$conf.int[length(summary$conf.int[,3]),3],d.round +1), " ; ", ... = round(summary$conf.int[length(summary$conf.int[,4]),4],d.round+1), "]"),
                     "p.value" = signif(summary$coefficient[length(summary$coefficient[,5]),5],3),
                     "pv_signif" = ifelse(summary$coefficient[length(summary$coefficient[,5]),5] <= alpha, "*"," "),
                     "p.shonfeld" = signif(test.shonfeld$table[dim(test.shonfeld$table)[1],dim(test.shonfeld$table)[2]],d.round+1),
                     "n" = model$n,
                     "n.events" = model$nevent,
                     "c_index" = round(c_index,3)
                     )
     
     
    return(list("res_df"=df, "model" = model))
   } 
   
   else if (round == F){
     
     df = data.frame("Name" = var,
                     "HR" = summary$coefficient[length(summary$coefficient[,2]),2],
                     "ICinf" = summary$conf.int[length(summary$conf.int[,3]),3],
                     "ICsup" = summary$conf.int[length(summary$conf.int[,4]),4],
                     "p.value" = summary$coefficient[length(summary$coefficient[,5]),5],
                     "pv_signif" = ifelse(summary$coefficient[length(summary$coefficient[,5]),5] <= alpha, 1,0),
                     "p.shonfeld" = signif(test.shonfeld$table[dim(test.shonfeld$table)[1],dim(test.shonfeld$table)[2]],d.round+1),
                     "Hyp.Prop.verif" = ifelse(test.shonfeld$table[dim(test.shonfeld$table)[1],dim(test.shonfeld$table)[2]] <= alpha ,0,1),
                     "n" = model$n,
                     "n.events" = model$nevent,
                     "c_index" = c_index
                     )
   
     return(df)
   
   }
}
```

Permet d'afficher les HR  de modèles univariés (Autant de paramètres qu'on veut pour 1 evenement particulier) avec un code couleur pour leur significativité.



```{r}
plot_pv_HR  = function(cox_nice_info, hj = 0, vj = 0, main = " "){
  
  # Pour pouvoir utiliser cette fonction il faut que cox_nice_info soit un objet cox_univar ou cox_multivar utilisé avec l'argument round = F
  
  # Extraction des noms des param et
  tmp = c()
  for(var in cox_nice_info$Name)
    {tmp = c(tmp,which(echotracking == var))}
  cox_nice_info$Name_nice = names_echotracking[tmp]
  
  # Colonne pour couleur et legende
   for(i in 1:nrow(cox_nice_info)){
     # hypoyhèse de proportionalité non vérifiée
     if(cox_nice_info[i,"Hyp.Prop.verif"] == 0)
     {cox_nice_info[i,"col"] = "Hyp non verified"}
     # non significatif
     else if ((cox_nice_info[i,"Hyp.Prop.verif"] == 1) & (cox_nice_info[i,"pv_signif"] == 0) )
     {cox_nice_info[i,"col"] = "Non significant"}
     # effet protecteur
     else if ((cox_nice_info[i,"Hyp.Prop.verif"] == 1) & (cox_nice_info[i,"pv_signif"] == 1) & (cox_nice_info[i,"HR"] <= 1))
     {cox_nice_info[i,"col"] = "Protective effect"}
     # effet deletere
     else if((cox_nice_info[i,"Hyp.Prop.verif"] == 1) & (cox_nice_info[i,"pv_signif"] == 1) & (cox_nice_info[i,"HR"] > 1))
     {cox_nice_info[i,"col"] = "Deleterious effect"}
   }
  cox_nice_info$col = as.factor(cox_nice_info$col)
  
  
  ggplot(cox_nice_info,aes(p.value, HR, color = col)) +

  geom_point(size = 3) +

  scale_y_continuous(name="HR",limits=c(min(cox_nice_info$HR)-0.1 , max(cox_nice_info$HR)+0.1)) +
    

  theme_classic() +

  geom_text_repel(aes(label = Name_nice),
                  segment.colour = NA,
                  box.padding   = 0.35,
                  point.padding = 0.5,
                  #segment.color = "black",
                  force = 5,
                  segment.size  = .7 ,#epaisseur segments
                  size = 3 #taille label
                     ) +


  labs(title = main, y = "Hazard Ratio", x = "p value", color = " ")
  
  #return(cox_nice_info[,c("Name","Name_nice")])
  
}
```

Idem que plot_pv_HR mais sans la catégorie de verification de l'hypothèse des risques proportionnels.

```{r}
plot_pv_HR2  = function(cox_nice_info, hj = 0, vj = 0, main = " "){
  
  # Pour pouvoir utiliser cette fonction il faut que cox_nice_info soit un objet cox_univar ou cox_multivar utilisé avec l'argument round = F
  
  # Extraction des noms des param et
  tmp = c()
  for(var in cox_nice_info$Name)
  {
    tmp = c(tmp,which(echotracking == var))
    }
   cox_nice_info$Name_nice = names_echotracking[tmp]
  

  # Colonne pour couleur et legende
   for(i in 1:nrow(cox_nice_info)){
     # non significatif
     if ((cox_nice_info[i,"pv_signif"] == 0) )
     {cox_nice_info[i,"col"] = "Non significant"}
     # effet protecteur
     else if ((cox_nice_info[i,"pv_signif"] == 1) & (cox_nice_info[i,"HR"] <= 1))
     {cox_nice_info[i,"col"] = "Reduction Risk"}
     # effet deletere
     else if((cox_nice_info[i,"pv_signif"] == 1) & (cox_nice_info[i,"HR"] > 1))
     {cox_nice_info[i,"col"] = "Increased Risk"}
   }
  cox_nice_info$col = as.factor(cox_nice_info$col)


  ggplot(cox_nice_info,aes(p.value, HR, color = col)) +

  geom_point(size = .5) +

  #scale_y_continuous(name="HR",limits=c(min(cox_nice_info$HR)-0.05 , max(cox_nice_info$HR)+0.05 )) +
  ylim(0,4) +

  theme_classic() +
  
  scale_color_manual(values = c("red", "black", "darkgreen ")) +
    theme(legend.position = "bottom") +

  geom_text_repel(aes(label = Name_nice)
                  ,
                  #segment.colour = NA,
                  #box.padding   = 0.35,
                  point.padding = 1.25,
                  #segment.color = "black",
                  #force = 5,
                  #segment.size  = .7 ,#epaisseur segments
                  size = 4 #taille label
                     ) +


  labs(title = main, y = "Hazard Ratio", x = "p value", color = " ")

  #return(cox_nice_info[,c("Name","Name_nice")])
  
}
```

Permet de fiter des régressions de cox multivariées et de récupérer les info du dernier coefficients qui correspond au paramètre d'échotracking que l'on étudie.


```{r}
cox_multivar2 = function(formula, list_param, dt, round = T, d.round = 2){
  
  df_res = data.frame()
  
    for(param in list_param){
      
      f = update(formula, as.formula( paste0(".~.+",param) ) )
      cox = coxph(f, data = dt)
      summary = summary(cox)
      c_index = concordance(cox)$concordance

      # Pour pouvoir acceder a dernier élément du tableau qui correspond au paramètre d'échotracking qu'on rajoute à la fin de chaque formula : 

      r = nrow(summary$coefficients)

      if(round == T){
          df_tmp = data.frame("Name" = rownames(summary$coefficients)[r],
                    "HR" = round(summary$coefficient[r,2],d.round),
                    "IC" = paste0("[", round(summary$conf.int[r,3],d.round), " ; ",round(summary$conf.int[r,4],d.round), "]"),
                    "p.value" = signif(summary$coefficient[r,5],d.round+3),
                    "Signif" = ifelse(summary$coefficient[r,5] <= 0.05, "*"," "),
                    "c_index" = round(c_index,3),
                    "n.event" = cox$nevent)

      }


      else if(round == F){
        df_tmp = data.frame("Name" = rownames(summary$coefficients)[r],
                    "HR" = summary$coefficient[r,2],
                    "ICinf" = summary$conf.int[r,3],
                    "ICsup" = summary$conf.int[r,4],
                    "p.value" = signif(summary$coefficient[r,5],d.round+3),
                    "c_index" = c_index,
                    "n.event" = cox$nevent)
        df_tmp$pv_signif = ifelse(df_tmp$p.value <= 0.05 , 1, 0)

       }

      df_res = rbind(df_res,df_tmp)
       }
   return(df_res)
}
```








Vérification de la loglinéarité de cox univariés avec la méthode du livre de biostat



```{r}
verifHyp_loglin_coxUnivar = function(var_verif, time, evt, dt, method = "center", nb.class = 4 ){
  #var_verif : (string) variable dont on veut prouver la log linéarité
  #time : (string) le time_to_evt
  #evt : (string) l'évenement
  #dt : (data.frame) le data frame contennant au moins var_verif, time et evt
  #method : (string) à choisir dans "center"(defaut), "mean", "median"
  #nb.class : (integer) nombre de classe à construire à partir de var_verif
  
  
  dt[,time] = as.numeric(dt[,time])
  dt[,evt] = as.numeric(dt[,evt])

  if(!(method %in% c("center", "mean", "median"))){return("method should be one of center, mean or median")}
  
  nb.class = round(nb.class,0)

  dt[,"var_verif_cat"] =lsr::quantileCut(dt[,var_verif],nb.class)
  
  
  res = data.frame("Levels"=rep(NA,nb.class),
                   "N"=rep(NA,nb.class),
                   "tmp"=rep(NA,nb.class),
                   "d"=rep(NA,nb.class),       "HR_computed"=rep(NA,nb.class),
            "HR_fitted"=rep(NA,nb.class),
                   "IC_fitted"=rep(NA,nb.class),
                   "verif" = rep(NA,nb.class))
  
  res$Levels = levels(dt$var_verif_cat)
  res$N = table(dt$var_verif_cat)
  
   if(method == "mean"){
      res$tmp=round(with(dt,tapply(dt[,var_verif],as.factor(dt[,"var_verif_cat"]),mean)),3)
    }
   
    else if(method == "center"){
      res$tmp= round(with(dt,tapply(dt[,var_verif],as.factor(dt[,"var_verif_cat"]),min)) +
        (with(dt,tapply(dt[,var_verif],as.factor(dt[,"var_verif_cat"]),max)) - with(dt,tapply(dt[,var_verif],as.factor(dt[,"var_verif_cat"]),min)))
        /2,0)
    }
   
    else if(method == "median"){
      res$tmp=round(with(dt,tapply(dt[,var_verif],as.factor(dt[,"var_verif_cat"]),median)),3)
    }
  
  res$d = res$tmp - res$tmp[1]
  res$d[1] = 1
  
  cox_cont = summary(coxph(Surv(dt[,time],dt[,evt]) ~ dt[,var_verif], data = dt))
  coef = cox_cont$coefficients[1,1]
  
  res$HR_computed = round(exp(res$d*coef),2)
  res$HR_computed[1] = 1
  
  cox_cat = summary(coxph(Surv(dt[,time],dt[,evt]) ~ var_verif_cat, data = dt))
  
  res$HR_fitted = round(c(1,cox_cat$coefficients[,2]),2)
  
  res$IC_fitted = c("ref.",paste("[",round(cox_cat$conf.int[,3],2),";",round(cox_cat$conf.int[,4],2),"]"))
  
  res$verif[1] = "ref."
  res$verif[2:nb.class] = ifelse((res$HR_computed[2:nb.class]>=cox_cat$conf.int[,3]) & (res$HR_computed[2:nb.class]<=cox_cat$conf.int[,4]) ,"*"," ")
  
  res$HR_computed = as.character(res$HR_computed)
  res$HR_computed[1] = "ref."
  res$HR_fitted = as.character(res$HR_fitted)
  res$HR_fitted[1] = "ref."
  res$N = as.character(res$N)

  return(res[,c("Levels","N","verif","HR_computed","HR_fitted","IC_fitted")])
  }

```

Retirer les outliers methode des quantiles
```{r}
cut_outlier_quantile = function(var,dt,pinf = 0.01){
  #dt: (data.frame) dataframe contennant au moins var
  #var: (string) variable dont on veut retirer les outliers
  #pinf: proportion de valeurs à retirer (borne inf)
  
  psup = 1-pinf
  binf = quantile(dt[,var],pinf, na.rm = T)
  bsup = quantile(dt[,var],psup, na.rm = T)
  out_idx = which(dt[,var] < binf | dt[,var] > bsup)
  var_new = dt[-out_idx,var]
  
  return(list("out_idx" = out_idx, "var_new" = var_new))
}
```
Stocker la legende d'un graphe
```{r}
get_legend =function(myggplot){
  tmp = ggplot_gtable(ggplot_build(myggplot))
  leg = which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}
```

Modèles de cox multivariés avec plusieurs paramètres d'echotracking

```{r}
cox_multivar_multi_param = function(tt_evt, evt, list_param, list_var_ajust, dt, round = T, d.round = 2){
  
  dt[,evt] = as.numeric(as.character(dt[,evt]))
  dt[,tt_evt] = as.numeric(as.character(dt[,tt_evt]))
  
  param = paste0(list_param, collapse = "+")
  var_ajust = paste0(list_var_ajust, collapse = "+")
  
  f = formula(paste0("Surv(",tt_evt,",", evt,")~", param,"+" ,var_ajust))
  
  cox = coxph(f,data = dt)
  summary = summary(cox)
  c_harell = round(concordance(cox)$concordance,3)

  r = 0
  for(p in list_param){
    if(is.numeric(dt[,p])){
      r = r+1}
    else if (is.factor(dt[,p]))
      {r = r + length(levels(dt[,p])) - 1}
  }


      if(round == T){
          df_tmp = data.frame("Name" = rownames(summary$coefficients)[1:r],
                    "HR" = round(summary$coefficient[1:r,2],d.round),
                    "IC" = paste0("[", round(summary$conf.int[1:r,3],d.round), " ; ",round(summary$conf.int[1:r,4],d.round), "]"),
                    "p.value" = signif(summary$coefficient[1:r,5],3),
                    "Signif" = ifelse(summary$coefficient[1:r,5] <= 0.05, "*"," ")
                    )

      }
       else if(round == F){
         df_tmp = data.frame("Name" = rownames(summary$coefficients)[1:r],
                     "HR" = summary$coefficient[1:r,2],
                     "ICinf" = summary$conf.int[1:r,3],
                     "ICsup" = summary$conf.int[1:r,4],
                     "p.value" = signif(summary$coefficient[1:r,5],d.round+3))
         df_tmp$pv_signif = ifelse(df_tmp$p.value <= 0.05 , 1, 0)



       }


  return(list("df" = df_tmp, "c_harell" = c_harell))
}
```
Permet de virer les sujets (identifiés par id, var devant être présente dans la base dt) ayant au moins une NA dans au moins une des variables de list_var.


```{r}
NRI_IDI_cox_tos = function(evt,v_ajust,v_, data, t=5){
  # evt: vecteur de taille nb.event*2 evt = (evt1,ttevt1,evt2,ttevt2,...)
  # v_ajust : vecteurs avec toutes les variables d'ajustement
  # v_ : paramètres dont on veut calculer l'apport predictif
  
T1<-Sys.time()

# Liste des résultats des modèles de base pour chaque evt
list_base = list()
# Liste des résultats des modèles enrichis pour chaque evt
list_base_param = list()

for ( i in seq(1,length(evt),2)) {
# Gestion des types des evt et time_to_evt
  data[,evt[i]] = as.numeric(as.character(data[,evt[i]]))
  data[,evt[i+1]] = as.numeric(as.character(data[,evt[i+1]]))
  
# Fit du Modèle de base
  var_formula = paste(v_ajust, collapse =" + ")
  formula_base = as.formula(paste("Surv(",evt[i+1],",",evt[i],")~",var_formula))
  mod_base = coxph(formula_base,data=data)
  sum_base = summary(mod_base)
  
# Test du rapport de vraisemblance des coefficients du modèle de base
  p_test = c()
  for(j in 1:length(v_ajust)){
    reste = v_ajust[-j]
    var_formula_test = paste(reste, collapse = "+")
    formula_test = as.formula(
      paste("Surv(",
            evt[i+1],",",
            evt[i],")~",var_formula_test))
    mod_test = coxph(formula_test, data = data)
    p = anova(mod_base,mod_test, test = "Chisq")$'P(>|Chi|)'[2]
    if(is.factor(data[,v_ajust[j]])){
      nb.levels = length(levels(data[,v_ajust[j]]))
      p = rep(p,nb.levels-1)
    }
    p_test = c(p_test,p)
  }
  p_test = ifelse(p_test<=0.001,"<0.001",signif(p_test,3))
  

# Liste avec les info du modèle de base
  HR_base = round(sum_base$conf.int[,1],2)
  IC_base = paste0("[", round(sum_base$conf.int[,3],2) , ";" , round(sum_base$conf.int[,4],2), "]" )
  p_base = ifelse(sum_base$coefficients[,5]<=0.001,"<0.001",signif(sum_base$coefficients[,5],3))
  cindex_base = signif(concordance(mod_base)$concordance,3)
  IC_cindex_base = paste0("[", 
                          round(concordance(mod_base)$concordance - 1.96*sqrt(concordance(mod_base)$var),2) ,
                          ";" , 
                          round(concordance(mod_base)$concordance + 1.96*sqrt(concordance(mod_base)$var),2),
                          "]")
  nevent_base = mod_base$nevent
  N_base = mod_base$n
  df_base = data.frame("Names" = row.names(sum_base$coefficients),
                       "HR" = HR_base,
                       "IC" = IC_base,
                       "p" = p_base,
                       "p.globale" = p_test
                       )

  list_base[[paste0(evt[i])]] = list("df" = df_base, "N" = N_base, "n.event" = nevent_base, "c.index" = cindex_base, "IC.c.index" = IC_cindex_base)
  
# Fit des modèles de base + 1 param 
  list_formulas_cox = sapply(v_, function(x)                  as.formula(paste("Surv(",evt[i+1],",",evt[i],")~",var_formula,"+",x)))
  names(list_formulas_cox) = v_
  
  
  list_models = lapply(list_formulas_cox,function(x){
    # Modèle
    m = coxph(x, data = data)
    # Clacul NRI et IDI
    v_base = attr(mod_base$terms,"term.labels")
    v_param = attr(m$terms,"term.labels")
    f_param = as.formula(paste0("~",paste(v_param, collapse = "+")))
    f_base = as.formula(paste0("~",paste(v_base, collapse = "+")))
    COVS0 = model.matrix(f_base, data)[,-1]
    COVS1 = model.matrix(f_param, data)[,-1]
    res = IDI.INF(indata = data[,c(evt[i+1],evt[i])],
                covs0 = COVS0,
                covs1 = COVS1,
                t0 = t*365)
    # Test du rapport de vraisemblance des coefficients du modèle de base
   p_test_param = c()
   for(j in 1:length(v_param)){
     reste = v_param[-j]
     var_f_base = paste(v_param, collapse = "+")
     var_f_param = paste(reste, collapse = "+")
     f_base = as.formula(
       paste("Surv(",
             evt[i+1],",",
             evt[i],")~",var_f_base))
     f_param = as.formula(
       paste("Surv(",
             evt[i+1],",",
             evt[i],")~",var_f_param))
     mod_base = coxph(f_base, data = data)
     mod_param = coxph(f_param, data = data)
     p = anova(mod_base,mod_param, test = "Chisq")$'P(>|Chi|)'[2]
     if(is.factor(data[,v_param[j]])){
       nb.levels = length(levels(data[,v_param[j]]))
       p = rep(p,nb.levels-1)
     }
     p_test_param = c(p_test_param,p)
   }
   p_test_param = ifelse(p_test_param<=0.001,"<0.001",signif(p_test_param,3))
    return(list("model" = m, "nri_idi" = res, "p.globale" = p_test_param ))
    
  })
                        
  names(list_models) = v_
  

  
  
  
# Liste des infos des modèles base + 1 paramètre d'echotracking
  
  list_models_nice = lapply(list_models,
                            function(x){
                              HR_param = round(summary(x$model)$conf.int[,1],2)
                              IC_param = paste0("[", round(summary(x$model)$conf.int[,3],2) , ";" ,round(summary(x$model)$conf.int[,4],2),"]" )
                              p_param = ifelse(summary(x$model)$coefficients[,5]<=0.001,"<0.001",signif(summary(x$model)$coefficients[,5],3))
                              p.globale_param = x$p.globale
                              cindex_param = signif(concordance(x$model)$concordance,3)
                              IC_cindex_param = paste0("[",round(concordance(x$model)$concordance-1.96*sqrt(concordance(x$model)$var),2) ,";" ,round(concordance(x$model)$concordance + 1.96*sqrt(concordance(x$model)$var),2),"]")
                              nevent_param = x$model$nevent
                              N_param = x$model$n
                              idi = signif(x$nri_idi$m1[1],3)
                              IC_idi = paste0("[",signif(x$nri_idi$m1[2],2),";",signif(x$nri_idi$m1[3],2),"]")
                              pv_idi = ifelse(x$nri_idi$m1[4] < 0.001, "<0.001",signif(x$nri_idi$m1[4],3))
                              idi_e =
signif(x$nri_idi$m1.est[2]-(1-x$nri_idi$m1.est[2]),3)                               
                              idi_ne = signif((1-x$nri_idi$m1.est[3])-x$nri_idi$m1.est[3],3)
                              demi_nri = signif(x$nri_idi$m2[1],3)
                              IC_demi_nri = paste0("[",signif(x$nri_idi$m2[2],2),";",signif(x$nri_idi$m2[3],2),"]")
                              pv_demi_nri = ifelse(x$nri_idi$m2[4] < 0.001, "<0.001",signif(x$nri_idi$m2[4],3))
                              nri = signif(2*x$nri_idi$m2[1],3)
                              
                              nri_e = signif(x$nri_idi$m2.est[2]-(1-x$nri_idi$m2.est[2]),3)
                              nri_ne = signif((1-x$nri_idi$m2.est[3])-x$nri_idi$m2.est[3],3)
                              
                              
                              return(list("df" = data.frame("HR" = HR_param, "IC" = IC_param, "p" = p_param, "p.globale"=p.globale_param), 
                                          "N" = N_param, 
                                          "n.event" = nevent_param, 
                                          "harell" = data.frame("c.index" = cindex_param, "IC.c.index" = IC_cindex_param), 
                                          "IDI" = data.frame("IDI" = idi, "IC_IDI" = IC_idi, "p_IDI" = pv_idi,"IDI_e" = idi_e ,"IDI_ne" = idi_ne),
                                          "NRI" = data.frame("NRI_0.5" = demi_nri,"IC_NRI_0.5" = IC_demi_nri, "p_NRI_0.5" = pv_demi_nri, "NRI" = nri, "NRI_evt" = nri_e, "NRI_n.evt" = nri_ne)
                                          )
                                     )
                              }
                            )

                              

  list_base_param[[paste0(evt[i])]] = list_models_nice
}

T2<-Sys.time()

return(list("list_base" = list_base,"list_base_param" = list_base_param,"tps.exe" = difftime(T2,T1)))
}
```

Likelihood ratio et Wald tests 

```{r}
global_test_cox = function(var_ajust, var_param, evt, tt_evt,dt ,test = "lr"){
  res = matrix(ncol = 2, nrow = length(c(var_param,var_ajust)))
  var_base = paste(c(var_param,var_ajust), collapse = "+")
  f_base = as.formula(paste("Surv(",tt_evt,",",evt,")~",var_base))
  for (j in 1:length(c(var_param,var_ajust))){
    reste = c(var_param,var_ajust)[-j]
    var_enrichi = paste(reste, collapse = "+")
    f_enrichi = as.formula(paste("Surv(",tt_evt,",",evt,")~",var_enrichi))

    
    if (test == "wald"){
      test_done = "Wald test"
    p = waldtest(coxph(f_base, data = dt),coxph(f_enrichi,data=dt))$`Pr(>Chisq)`[2]
    }
      
    
    else{
    test_done = "Likelihood ratio test"
    p = lrtest(coxph(f_base, data = dt),coxph(f_enrichi,data=dt))$`Pr(>Chisq)`[2]
    }

    
    
    res[j,1] = c(var_param,var_ajust)[j]
    res[j,2] = ifelse(p<=0.001,"<0.001",signif(p,3))
  }
  print(test_done)
  return(res)
}

```

```{r}
clean_cox_model = function (model, data = NULL, main = "Hazard ratio", 
                       cpositions = c(0.02, 0.22, 0.4), 
                       fontsize = 0.7, refLabel = "reference", noDigits = 2,

                       # new parameters with some default values; function's behaviour
                       # does not differ from ggforest() unless arrow = TRUE
                       arrow = FALSE, arrow.labels = c("left", "right"), 
                       arrow.specification = arrow(), arrow.colour = "black") {

  # this part is unchanged
  conf.high <- conf.low <- estimate <- NULL
  stopifnot(class(model) == "coxph")
  data <- survminer:::.get_data(model, data = data)
  terms <- attr(model$terms, "dataClasses")[-1]
  terms <- terms[intersect(names(terms), 
                           gsub(rownames(anova(model))[-1], pattern = "`", replacement = ""))]
  allTerms <- lapply(seq_along(terms), function(i) {
    var <- names(terms)[i]
    if (terms[i] == "factor") {
      adf <- as.data.frame(table(data[, var]))
      cbind(var = var, adf, pos = 1:nrow(adf))
    }
    else {
      data.frame(var = var, Var1 = "", Freq = nrow(data), pos = 1)
    }
  })
  allTermsDF <- do.call(rbind, allTerms)
  colnames(allTermsDF) <- c("var", "level", "N", "pos")
  inds <- apply(allTermsDF[, 1:2], 1, paste0, collapse = "")
  coef <- as.data.frame(broom::tidy(model))
  gmodel <- broom::glance(model)
  rownames(coef) <- gsub(coef$term, pattern = "`", replacement = "")
  toShow <- cbind(allTermsDF, coef[inds, ])[, c("var", "level", "N", "p.value", "estimate", 
                                                "conf.low", "conf.high", "pos")]
  toShowExp <- toShow[, 5:7]
  toShowExp[is.na(toShowExp)] <- 0
  toShowExp <- format(exp(toShowExp), digits = noDigits)
  toShowExpClean <- data.frame(toShow, pvalue = signif(toShow[, 4], noDigits + 1), toShowExp)
  toShowExpClean$stars <- paste0(round(toShowExpClean$p.value, noDigits + 1), " ", 
                                 ifelse(toShowExpClean$p.value < 0.05, "*", ""), 
                                 ifelse(toShowExpClean$p.value < 0.01, "*", ""), 
                                 ifelse(toShowExpClean$p.value < 0.001, "*", ""))
  toShowExpClean$ci <- paste0("(", toShowExpClean[, "conf.low.1"], 
                              " - ", toShowExpClean[, "conf.high.1"], ")")
  toShowExpClean$estimate.1[is.na(toShowExpClean$estimate)] = refLabel
  toShowExpClean$stars[which(toShowExpClean$p.value < 0.001)] = "<0.001 ***"
  toShowExpClean$stars[is.na(toShowExpClean$estimate)] = ""
  toShowExpClean$ci[is.na(toShowExpClean$estimate)] = ""
  toShowExpClean$estimate[is.na(toShowExpClean$estimate)] = 0
  toShowExpClean$var = as.character(toShowExpClean$var)
  toShowExpClean$var[duplicated(toShowExpClean$var)] = ""
  toShowExpClean$N <- paste0("(N=", toShowExpClean$N, ")")
  toShowExpClean <- toShowExpClean[nrow(toShowExpClean):1, ]
  rangeb <- range(toShowExpClean$conf.low, toShowExpClean$conf.high, 
                  na.rm = TRUE)
  breaks <- axisTicks(rangeb/2, log = TRUE, nint = 7)
  rangeplot <- rangeb
  rangeplot[1] <- rangeplot[1] - diff(rangeb)
  rangeplot[2] <- rangeplot[2] + 0.15 * diff(rangeb)
  width <- diff(rangeplot)
  y_variable <- rangeplot[1] + cpositions[1] * width
  y_nlevel <- rangeplot[1] + cpositions[2] * width
  y_cistring <- rangeplot[1] + cpositions[3] * width
  y_stars <- rangeb[2]
  x_annotate <- seq_len(nrow(toShowExpClean))
  annot_size_mm <- fontsize * as.numeric(grid::convertX(unit(theme_get()$text$size, "pt"), "mm"))
  return(toShowExpClean)
}

```
